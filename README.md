# 要求
(1）部署一个通义干问1.5B、4B，或者 DEEPSEEK 1.5B、7B的模型，如果没有显卡，尝试使用 CPU 部署；(2）能够进行基本的短文本问答；
额外内容：(1）制作个人知识库，对部署的模型进行 RAG ，能够输入自己的姓名等，进行正确的问答；(2）使用微调等其他手段，提高模型对于个人、对于山东大学的回答正确率。

# Retriever 检索器
## 功能介绍
实现了一个基于语义嵌入的文本检索系统，核心功能是通过计算文本相似度从大型文档库中高效检索相关段落。主要功能包括：

1. **语义检索**
输入查询语句，返回文档中语义最相关的top-k段落
基于余弦相似度计算查询与文档片段的匹配度

2. **智能缓存机制**
使用MD5校验文件修改状态
自动复用预计算的嵌入向量，避免重复处理

3. **文本预处理**
按自然语言边界（句末标点/换行符）智能分块
保留文本来源和位置元数据


## m3e-base模型
m3e-base 是由 MokaAI 开源发布的 中文-多语句向量模型（Multilingual Massive Message Embedding），其核心任务是将自然语言文本（如句子、段落）编码为 高维稠密向量（dense embedding），用于语义匹配、检索、问答等下游任务。

## 相似度计算
句子向量是高维向量空间中的点或方向，衡量两个句子语义相似度的核心指标是**余弦相似度**，计算公式如下：

$$
\text{sim}(A,B) = \cos(\theta) = \frac{A \cdot B}{\|A\| \cdot \|B\|}
$$

## 符号说明

| 符号        | 含义                          | 数学表达                     |
|-------------|-----------------------------|----------------------------|
| $A, B$      | 待比较的两个句子/段落的向量           | $\in \mathbb{R}^d$         |
| $\cdot$     | 向量点积运算                     | $A \cdot B = \sum_{i=1}^d A_iB_i$ |
| $\|A\|$     | 向量的L2范数（模长）               | $\sqrt{\sum_{i=1}^d A_i^2}$ |
| $\theta$    | 向量间的夹角, 越小越相似              | $\theta \in [0, \pi]$       |

# llm_interface LLM接口
## 功能介绍
实现了一个基于Qwen大语言模型（LLM）的问答系统接口，核心功能是根据用户查询和上下文信息生成高质量回答。主要功能包括：

1. **智能问答生成**
   支持纯问题回答（无上下文模式）
   支持上下文增强回答（检索增强生成RAG模式）
   自动区分信息充足/不足场景
2. **对话管理**
   动态生成System Prompt引导模型行为
   结果解析
3. **安全控制**
   显式声明知识边界
   空回答兜底处理
   确定性生成模式

## 确定性生成模式
工作机制: 在每一步 token 生成中，模型会计算所有候选词的概率分布，然后始终选取概率最大的那个（argmax）。
适合作为问答系统精确稳定地回答问题

* 随机采样生成: 只从概率最高的前 k 个 token 中采样, 输出不一致

## assistant 对话角色
对话上下文中的角色标签，用于告诉模型“这段内容是由 AI 回答的”。它属于 Prompt 模板机制中的一部分，用于模拟「AI助手」的身份与行为。
模型会默认预测assistant的回答

# main
## 功能分析
该程序实现了一个基于检索增强生成（RAG）的智能问答系统，核心功能是根据用户查询动态选择最优回答策略。启动时实例化 Retriever 与 QwenLLM，交互中先执行 Top‑5 向量检索。主要功能包括：

1. **多策略回答引擎**
本地知识优先策略（local）：强制使用特定关键词相关段落
RAG策略（rag）：使用语义检索结果生成回答
纯模型策略（model）：直接使用LLM知识回答

2. **智能意图识别**
关键词检测
检索结果质量评估（相似度阈值0.5）

3. **上下文优化**
主语提取与结果过滤
相似度加权上下文构建
检索失败时的本地知识兜底

